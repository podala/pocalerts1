# Executive Summary

This document proposes an **Excel→Python Migration Factory** to convert actuarial/underwriting Excel logic into scalable, governed Python rules—targeting **100× throughput** with consistent quality and auditability.

**Core idea:** treat formulas as *business rules* with data contracts, automate extraction + conversion with LLM-assisted tooling, validate against golden datasets, and deploy a rule engine (PySpark-ready) that produces consistent outputs and Mongo-ready payloads.

---

## 1) Outcomes & KPIs

* **Throughput:** ≥ 200 formulas/day/team (automation first pass ≥ 85%).
* **Accuracy:** ≥ 99.5% match against Excel across golden test sets.
* **Cycle Time:** < 24h from intake → validated Python rule.
* **Coverage:** All priority templates/rate types (AWP, WAC, BASE, MAF, PPL, PPA).
* **Auditability:** Full lineage from Excel cell → business rule → Python → output.

---

## 2) Target-State Architecture (Improved)

```
Source: Excel workbooks (.xlsx/.xlsb)
    │
[A] Formula Extractor
    - Sheet/zone detection (tabular, field, matrix blocks)
    - Dual-row headers & cross-sheet references
    - Emits: ExtractedFormula JSON + Tables JSON
    │
[B] Business Mapping Catalog (Managed)
    - Column map (Excel cell ↔ business field)
    - Table map (named ranges ↔ logical tables)
    - Versioned in Git; editable by analysts via UI
    │
[C] Pattern Library
    - Canonical patterns: IF/ELSE, IFERROR, INDEX/MATCH, LOOKUP matrices,
      year-scoped rules, multi-key lookups, brand/generic switches
    - Each pattern has JSON schema + test fixtures
    │
[D] LLM Orchestrator (Guardrailed)
    - Structured prompts (no freeform reasoning capture)
    - Uses: ExtractedFormula + Mapping Catalog + Pattern Library
    - Output 1: Stage-1 Analysis (conditions, inputs, lookups)
    - Output 2: Stage-2 Rule JSON (engine-ready)
    │
[E] Rule JSON Validator
    - Schema validation, static checks, unit tests autogen
    │
[F] Rule Engine (Python/PySpark)
    - Rule_Parser: compiles Rule JSON → vectorized ops
    - Rule_Executor: per-year isolation; parallel execution
    - Group-level aggregation & dependencies
    │
[G] Validation Harness
    - Golden datasets from Excel; diff engine; quality gates
    │
[H] Payload Builder (Mongo)
    - `ra_output` + rule-group outputs in wide format per NDC
    - Versioned payloads with metadata
    │
[I] Observability & Governance
    - Run logs, data lineage, rule registry, approvals, SLA dashboards
```

**Improvements vs current sketch**

* Adds **Mapping Catalog** and **Pattern Library** as first-class artifacts to dramatically increase repeatability.
* Introduces **Rule JSON Validator** + **Validation Harness** with golden datasets for accuracy guarantees.
* Makes **year-scoped execution** explicit (no cross-year side-effects).
* Formal **Observability & Governance** for audit/regulatory needs.

---

## 3) Business Process (Factory Flow)

1. **Intake** (Analyst/Underwriter): submit workbook + context (rate type, years, channels).
2. **Extraction** (Automated): parse formulas, detect zones, resolve references.
3. **Mapping** (Analyst): approve or edit field/table mappings in the Catalog.
4. **Generation** (Automated): LLM Orchestrator converts to Stage-1 Analysis → Stage-2 Rule JSON using patterns.
5. **Validation** (Automated): schema checks + autogen unit tests; run against Excel golden data.
6. **Review** (Reviewer): diff report shows pass/fail; comments & fixes loop.
7. **Publish** (Release Manager): rule registered, versioned; payload spec locked.
8. **Execution** (Ops): PySpark job executes at scale; outputs stored to Mongo.
9. **Monitoring** (Ops/QA): dashboards for SLA, error rates, and drift.

**RACI**

* **A/R:** Migration Lead
* **C:** Actuary/Underwriter, Data Engineering Lead
* **I:** Product/Compliance

---

## 4) Data Contracts (Schemas)

### 4.1 ExtractedFormula JSON

```json
{
  "sheet": "BasePricing",
  "cell": "AZ11",
  "formula": "IF(IFERROR(INDEX(Table1,...),0)>0, ...)",
  "references": ["AZ11","AG10","Table1"]
}
```

### 4.2 Mapping Catalog (example)

```json
{
  "version": "2025-08-10",
  "fields": {
    "AZ11": "ShiftScriptsNoCoT{year}",
    "AG10": "ShiftScriptsCoT{year}",
    "V10": "Script{year}",
    "O10": "MSB",
    "AV10": "Generic_Ind"
  },
  "tables": {
    "SP_Indicator_Reference": {
      "key": "SP_Indicator",
      "cols": ["W_O_GF","W_GF"]
    },
    "Formulary_Reference": {
      "key": "Formulary",
      "cols": ["MSBShift"]
    }
  }
}
```

### 4.3 Rule JSON (engine-ready)

```json
{
  "name": "shifted_script_rule",
  "group": "shifted_script",
  "applies_to_years": ["1"],
  "conditions": {"all": [{"path": "$.input_Shift", "operator": "equal", "value": "No"}]},
  "calculation": {"type": "value_path", "value_path": "$.Script{year}"},
  "else": {
    "type": "expression",
    "value": "$.ShiftScriptsNoCoT{year} * ($.inclusion_code[$.Length] == $.Value_ut ? $.table_yearID_{year} : 1) * ($.MSB == 1 and $.Generic_Ind == 'B' ? $.msb_percentage : 1)"
  }
}
```

### 4.4 Mongo Payload (per NDC, wide format)

```json
{
  "NDC": "123456789",
  "ra_output": { "...": "..." },
  "rules_output": {
    "shifted_script": {
      "2025": 3.078,
      "2026": 7.70,
      "2027": 7.35,
      "2028": 7.00,
      "2029": 6.65
    },
    "rebate_formula": { "2025": 0.12, "2026": 0.13 }
  },
  "meta": {"rule_versions": {"shifted_script": "v1.4.2"}}
}
```

---

## 5) Prompt Templates (Guardrailed)

### 5.1 Stage‑1: Structured Analysis

* Inputs: ExtractedFormula JSON, Mapping Catalog, Pattern Library
* Output: JSON with **conditions**, **inputs**, **lookups**, **dynamic columns**, **fallbacks**

**Template excerpt**

```
You are a rules analyst. Return ONLY valid JSON.
Given: {ExtractedFormula}, {FieldMap}, {TableMap}
Identify: conditions, inputs, lookups (table, key, return_col, fallback), dynamic columns.
```

### 5.2 Stage‑2: Rule Generation

* Inputs: Stage‑1 JSON + Pattern Library
* Output: Engine‑ready Rule JSON adhering to schema 4.3

**Template excerpt**

```
Generate Rule JSON following this schema: {RuleSchema}.
- Use year‑scoped placeholders {year}.
- No free text. Use operators from allowed list.
- If lookup present, emit value_path or expression using mapped fields only.
```

---

## 6) Quality Gates & Testing

* **Schema Validation:** JSON schema + enum/operator checks.
* **Static Checks:** field existence, no unresolved {year}, no raw Excel refs.
* **Unit Tests (autogen):** from Stage‑1 examples; boundary and null cases.
* **Golden Diff:** compare Python output vs Excel for 2025–2029 per NDC.
* **Thresholds:** hard fail if >0.5% variance or any NaN where Excel has value.

**Artifacts produced per rule**

1. Rule JSON; 2) Test dataset; 3) Unit tests; 4) Diff report (PDF/HTML); 5) Approval record.

---

## 7) Operating Model

* **Analyst (Business):** confirms mappings, reviews diffs.
* **Rule Engineer (Python):** pattern additions, engine extensions.
* **Migration Lead:** triage, SLAs, approvals.
* **Ops (Data Eng):** Spark jobs, monitoring, capacity.
* **Compliance:** audit, change management.

**Cadence**

* Daily standup; weekly release train; monthly KPI review.

---

## 8) Execution at Scale (100×)

* **Parallelization:** per‑rule, per‑year isolation; Spark partitions by NDC.
* **Caching:** broadcast small lookup tables; Delta cache for hot data.
* **Idempotent Jobs:** re‑run safe; checkpointed stages.
* **Self‑Service UI:** mapping edits, re‑gen rules, view diffs, download payloads.
* **Rule Registry:** semantic versioning; deprecations; dependency graph.

---

## 9) Rollout Plan

**Phase 0 (1–2 wks):** stand up extractor, catalog, 5 patterns, registry.
**Phase 1 (3–4 wks):** automate Stage‑1/2, validator, 20 high‑value rules.
**Phase 2 (4–6 wks):** Spark scale-out, golden datasets, dashboards.
**Phase 3 (ongoing):** expand pattern library, auto‑repair suggestions, drift alerts.

---

## 0) Risks & Mitigations

* **Ambiguous mappings →** require analyst approval + UI diffs.
* **Exotic Excel functions →** add pattern stubs + human review lane.
* **Data drift →** scheduled validation against control cohorts.
* **Over‑fitting prompts →** pattern-driven generation; continuous tests.

---

## 11) Appendix A — Allowed Operators

`equal, not_equal, greater_than, less_than, greater_or_equal, less_or_equal, and, or`

## 12) Appendix B — Example Pattern: INDEX/MATCH → lookup()

* Inputs: table, key\_path, return\_col
* Emission: `value_path` if direct; else `expression` referencing lookup cache.

## 13) Appendix C — Rule Group Dependencies

* Example: `shifted_script` → `rebate_formula` (reads output as input)
* Managed in registry with topological sort at execution time.

---

**This factory design enables non-Python analysts to drive conversions while engineering safeguards quality, speed, and scale.**
