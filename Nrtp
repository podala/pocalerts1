import pandas as pd
import json
import logging
import time
from functools import wraps

# Configure Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Decorators

def log_execution(func):
    """ Logs function execution details. """
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        logging.info(f"Executing: {func.__name__}")
        try:
            result = func(*args, **kwargs)
            logging.info(f"Completed: {func.__name__} in {time.time() - start_time:.4f} seconds")
            return result
        except Exception as e:
            logging.error(f"Error in {func.__name__}: {e}")
            raise
    return wrapper

class ScriptsProcessor:
    def __init__(self, config):
        self.config = config
        self.field_names = config["field_names"]
        logging.info("‚úÖ Initialized ScriptsProcessor")

    @log_execution
    def extract_pl_id(self, df, vector_index):
        """ Extracts the PL ID from the 'PL Information' header. """
        for _, row in df.iterrows():
            if row["header"] in self.config["header_groups"]["PL_Information"]["headers"] and row["kpi"] == "PL ID":
                pl_id = row.get(f"vector {vector_index}", "")
                logging.info(f"üîç Extracted PL ID: {pl_id}")
                return pl_id
        logging.warning(f"‚ö†Ô∏è PL ID not found for vector {vector_index}")
        return ""

    @log_execution
    def process_vector(self, df, vector_index):
        logging.info(f"üîÑ Processing vector {vector_index}")

        headers_list = []
        pl_id = self.extract_pl_id(df, vector_index)

        for _, row in df.iterrows():
            header_name = row["header"].strip()
            
            if header_name in self.config["header_groups"]["Scripts"]["headers"]:
                kpi_name = row["kpi"].strip()
                value = row.get(f"vector {vector_index}", "").strip()
                logging.info(f"üìå Processing row: header={header_name}, kpi={kpi_name}, value={value}")

                # Handling KPI Splitting - Ensuring Correct Parsing
                category_parts = kpi_name.rsplit("-", 2)  # Preserve brand names
                logging.info(f"üõ†Ô∏è Split Parts: {category_parts}")

                category, subCategory, year = None, None, None

                if len(category_parts) == 3:
                    category, subCategory, year = category_parts
                elif len(category_parts) == 2:
                    category, year = category_parts
                    subCategory = None
                else:
                    logging.warning(f"‚ö†Ô∏è Skipping invalid KPI format: {kpi_name}")
                    continue

                if year and str(year).isdigit():
                    try:
                        year = int(year.strip())
                        logging.info(f"‚úÖ Converted Year: {year}")
                    except ValueError:
                        logging.error(f"‚ùå Failed to convert year: {year}")
                        continue  # Skip if year conversion fails

                category_key = self.field_names["categories"]
                category_name_key = self.field_names["categoryName"]
                subcategory_name_key = self.field_names["subCategoryName"]
                yearly_data_key = self.field_names["yearlyData"]
                year_key = self.field_names["year"]
                value_key = self.field_names["value"]

                logging.info(f"üîç Checking header: {header_name}")

                # **Ensure header is created**
                header_obj = next((h for h in headers_list if h[self.field_names["headerName"]] == header_name), None)
                if not header_obj:
                    header_obj = {
                        self.field_names["headerName"]: header_name,
                        "vector": vector_index,
                        category_key: []
                    }
                    headers_list.append(header_obj)
                    logging.info(f"‚úÖ Created new header: {header_name}")

                # **Ensure category is added**
                logging.info(f"üîç Checking category: {category}")
                category_obj = next((c for c in header_obj[category_key] if c[category_name_key] == category), None)
                if not category_obj:
                    category_obj = {category_name_key: category, subcategory_name_key: []}
                    header_obj[category_key].append(category_obj)
                    logging.info(f"‚úÖ Added category: {category}")

                # **Ensure subCategory is added**
                if subCategory:
                    logging.info(f"üîç Checking subCategory: {subCategory}")

                    subcategory_obj = next((sc for sc in category_obj[subcategory_name_key] if sc[subcategory_name_key] == subCategory), None)
                    if not subcategory_obj:
                        subcategory_obj = {subcategory_name_key: subCategory, yearly_data_key: []}
                        category_obj[subcategory_name_key].append(subcategory_obj)
                        logging.info(f"‚úÖ Added subCategory: {subCategory}")

                    subcategory_obj[yearly_data_key].append({year_key: year, value_key: value})
                    logging.info(f"‚úÖ Added value to subCategory: {subcategory_obj}")
                else:
                    category_obj[subcategory_name_key].append({yearly_data_key: [{year_key: year, value_key: value}]})
                    logging.info(f"‚úÖ Added value to category: {category_obj}")

        final_document = {
            "PL ID": pl_id,
            "vector": vector_index,
            "headers": headers_list
        }

        logging.info(f"üìú Final JSON Payload for vector {vector_index}: {json.dumps(final_document, indent=4)}")

        output_file = f"scripts_vector_{vector_index}.json"
        with open(output_file, "w") as f:
            json.dump(final_document, f, indent=4)
        logging.info(f"‚úÖ Successfully saved JSON output to {output_file}")

        return final_document

@log_execution
def process_scripts(csv_file, config):
    logging.info("üöÄ Starting Scripts CSV Processing")
    df = pd.read_csv(csv_file)
    processor = ScriptsProcessor(config)

    for vector_index in range(1, 6):
        processor.process_vector(df, vector_index)

if __name__ == "__main__":
    csv_file = "input_data.csv"
    
    config = {
        "header_groups": {
            "Scripts": {
                "headers": ["Scripts", "Eligibility Scripts"]
            },
            "PL_Information": {
                "headers": ["PL Information"]
            }
        },
        "field_names": {
            "headerName": "headerName",
            "categories": "categories",
            "categoryName": "categoryName",
            "subCategoryName": "subCategories",
            "yearlyData": "yearlyData",
            "year": "year",
            "value": "value"
        }
    }

    logging.info("üöÄ Starting ScriptsProcessor Execution")
    process_scripts(csv_file, config)
