{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start the bulk movement of 100 members\n",
      "initiate the bulk transfer of 250 members for program general\n",
      "start the bulk movement of 50 members for state HA\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define templates for the default transfer operation\n",
    "default_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quant\n",
    "To include an additional variable called source in the DataFrame, where the source is set to \"user\" for each statement, you can easily extend the dictionaries being appended to the all_statements list to include this new key-value pair. Here's how you can modify the existing code to achieve this:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Define templates for the different transfer operations, including 'from user {user}'\n",
    "default_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members from user {user}\",\n",
    "    \"begin transferring {quantity} members in bulk from user {user}\",\n",
    "    \"start the bulk movement of {quantity} members from user {user}\",\n",
    "]\n",
    "\n",
    "program_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members for program general from user {user}\",\n",
    "    \"begin transferring {quantity} members in bulk for program general from user {user}\",\n",
    "    \"start the bulk movement of {quantity} members for program high risk from user {user}\",\n",
    "]\n",
    "\n",
    "state_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members for state TX from user {user}\",\n",
    "    \"begin transferring {quantity} members in bulk for state NA from user {user}\",\n",
    "    \"start the bulk movement of {quantity} members for state HA from user {user}\",\n",
    "]ity} members\",\n",
    "    \"begin transferring {quantity} members in bulk\",\n",
    "    \"start the bulk movement of {quantity} members\",\n",
    "]\n",
    "\n",
    "# Define templates for the program-specific transfer operation\n",
    "program_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members for program general\",\n",
    "    \"begin transferring {quantity} members in bulk for program general\",\n",
    "    \"start the bulk movement of {quantity} members for program high risk\",\n",
    "]\n",
    "\n",
    "# Define templates for the state-specific transfer operation\n",
    "state_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members for state TX\",\n",
    "    \"begin transferring {quantity} members in bulk for state NA\",\n",
    "    \"start the bulk movement of {quantity} members for state HA\",\n",
    "]\n",
    "\n",
    "def generate_transfer_sentence(label, quantity):\n",
    "    if label == 'default':\n",
    "        template = random.choice(default_transfer_templates)\n",
    "    elif label == 'program transfer':\n",
    "        template = random.choice(program_transfer_templates)\n",
    "    elif label == 'state transfer':\n",
    "        template = random.choice(state_transfer_templates)\n",
    "    else:\n",
    "        return \"Label not recognized.\"\n",
    "    \n",
    "    return template.format(quantity=quantity)\n",
    "\n",
    "# Example usage:\n",
    "print(generate_transfer_sentence('default', '100'))\n",
    "print(generate_transfer_sentence('program transfer', '250'))\n",
    "print(generate_transfer_sentence('state transfer', '50'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statements saved to transfer_statements.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define templates for the different transfer operations\n",
    "default_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members\",\n",
    "    \"begin transferring {quantity} members in bulk\",\n",
    "    \"start the bulk movement of {quantity} members\",\n",
    "]\n",
    "\n",
    "program_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members for program general\",\n",
    "    \"begin transferring {quantity} members in bulk for program general\",\n",
    "    \"start the bulk movement of {quantity} members for program high risk\",\n",
    "]\n",
    "\n",
    "state_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members for state TX\",\n",
    "    \"begin transferring {quantity} members in bulk for state NA\",\n",
    "    \"start the bulk movement of {quantity} members for state HA\",\n",
    "]\n",
    "\n",
    "# Function to generate statements\n",
    "def generate_transfer_statements(label, templates, quantity_range=(50, 500), count=100):\n",
    "    statements = []\n",
    "    for _ in range(count):\n",
    "        template = random.choice(templates)\n",
    "        quantity = random.randint(*quantity_range)\n",
    "        statement = template.format(quantity=quantity)\n",
    "        statements.append(f\"{statement},{label}\")\n",
    "    return statements\n",
    "\n",
    "# Generate statements for each label\n",
    "default_statements = generate_transfer_statements('default', default_transfer_templates)\n",
    "program_statements = generate_transfer_statements('program transfer', program_transfer_templates)\n",
    "state_statements = generate_transfer_statements('state transfer', state_transfer_templates)\n",
    "\n",
    "# Combine all statements\n",
    "all_statements = default_statements + program_statements + state_statements\n",
    "\n",
    "# Save to a file\n",
    "file_path = \"transfer_statements.csv\"\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(\"statement,label\\n\")\n",
    "    for statement in all_statements:\n",
    "        file.write(f\"{statement}\\n\")\n",
    "\n",
    "print(f\"Statements saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to augmented_transfer_statements.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define templates for the different transfer operations\n",
    "default_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members\",\n",
    "    \"begin transferring {quantity} members in bulk\",\n",
    "    \"start the bulk movement of {quantity} members\",\n",
    "]\n",
    "\n",
    "program_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members for program general\",\n",
    "    \"begin transferring {quantity} members in bulk for program general\",\n",
    "    \"start the bulk movement of {quantity} members for program high risk\",\n",
    "]\n",
    "\n",
    "state_transfer_templates = [\n",
    "    \"initiate the bulk transfer of {quantity} members for state TX\",\n",
    "    \"begin transferring {quantity} members in bulk for state NA\",\n",
    "    \"start the bulk movement of {quantity} members for state HA\",\n",
    "]\n",
    "\n",
    "# Pre-defined synonyms dictionary (simplified for demonstration)\n",
    "synonyms = {\n",
    "    \"initiate\": [\"start\", \"begin\", \"commence\"],\n",
    "    \"transfer\": [\"move\", \"shift\", \"relocate\"],\n",
    "    \"bulk\": [\"mass\", \"large amount\", \"majority\"],\n",
    "    # Add more as needed\n",
    "}\n",
    "\n",
    "# Function to generate statements\n",
    "def generate_transfer_statements(label, templates, quantity_range=(50, 500), count=100):\n",
    "    statements = []\n",
    "    for _ in range(count):\n",
    "        template = random.choice(templates)\n",
    "        quantity = random.randint(*quantity_range)\n",
    "        statement = template.format(quantity=quantity)\n",
    "        statements.append(f\"{statement},{label}\")\n",
    "    return statements\n",
    "\n",
    "# Function for manual synonym replacement (simplified version)\n",
    "def manual_synonym_replacement(sentence):\n",
    "    words = sentence.split()\n",
    "    new_sentence = []\n",
    "    for word in words:\n",
    "        # If the word has predefined synonyms, randomly choose one\n",
    "        if word in synonyms:\n",
    "            new_word = random.choice(synonyms[word])\n",
    "            new_sentence.append(new_word)\n",
    "        else:\n",
    "            new_sentence.append(word)\n",
    "    return ' '.join(new_sentence)\n",
    "\n",
    "# Generate and augment statements\n",
    "all_statements = []\n",
    "for label, templates in [(\"default\", default_transfer_templates), (\"program transfer\", program_transfer_templates), (\"state transfer\", state_transfer_templates)]:\n",
    "    original_statements = generate_transfer_statements(label, templates)\n",
    "    for statement in original_statements:\n",
    "        # Augment each statement by replacing synonyms\n",
    "        sentence, _ = statement.split(',')\n",
    "        augmented_sentence = manual_synonym_replacement(sentence)\n",
    "        all_statements.append(f\"{augmented_sentence},{label}\")\n",
    "\n",
    "# Save the data to a CSV file\n",
    "csv_file_path = \"augmented_transfer_statements.csv\"\n",
    "with open(csv_file_path, \"w\") as file:\n",
    "    file.write(\"statement,label\\n\")  # Write the CSV header\n",
    "    for statement in all_statements:\n",
    "        file.write(statement + \"\\n\")  # Write each statement\n",
    "\n",
    "print(f\"Data saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'commence the majority move of 88 members,default'\n",
      "'start the majority movement of 259 members,default'\n",
      "'start the majority shift of 303 members,default'\n",
      "'start the mass relocate of 351 members,default'\n",
      "'begin transferring 72 members in mass,default'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Pretty print the first 5 items\n",
    "for item in all_statements[:5]:\n",
    "    pprint(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             statement          target\n",
      "0             commence the majority move of 88 members         default\n",
      "1           start the majority movement of 259 members         default\n",
      "2              start the majority shift of 303 members         default\n",
      "3               start the mass relocate of 351 members         default\n",
      "4                begin transferring 72 members in mass         default\n",
      "..                                                 ...             ...\n",
      "295  start the large amount movement of 125 members...  state transfer\n",
      "296  start the large amount movement of 124 members...  state transfer\n",
      "297  begin transferring 326 members in large amount...  state transfer\n",
      "298  start the mass movement of 329 members for sta...  state transfer\n",
      "299  start the majority shift of 269 members for st...  state transfer\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split each message into statement and target, and store in a list\n",
    "data = [message.split(',') for message in all_statements]\n",
    "\n",
    "# Convert the list of data into a DataFrame\n",
    "df = pd.DataFrame(data, columns=['statement', 'target'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   statement  300 non-null    object\n",
      " 1   target     300 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target                              corrected_text\n",
      "0  default    commence the majority move of 88 members\n",
      "1  default  start the majority movement of 259 members\n",
      "2  default     start the majority shift of 303 members\n",
      "3  default      start the mass delicate of 351 members\n",
      "4  default       begin transferring 72 members in mass\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Custom preprocessing function for spell correction and converting to lowercase\n",
    "def preprocess_text(text):\n",
    "    # Correct spelling using TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = str(blob.correct())\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    corrected_text = corrected_text.lower()\n",
    "    \n",
    "    return corrected_text\n",
    "\n",
    "# Function to process the DataFrame\n",
    "def process_dataframe(df):\n",
    "    # Copy the 'label' column from the original DataFrame to preserve it\n",
    "    processed_df = pd.DataFrame()\n",
    "    processed_df['target'] = df['target']\n",
    "    \n",
    "    # Apply the preprocessing function to the 'message' column and save in 'corrected_text'\n",
    "    processed_df['corrected_text'] = df['statement'].apply(preprocess_text)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Process the DataFrame\n",
    "processed_df = process_dataframe(df)\n",
    "\n",
    "# Display the processed DataFrame\n",
    "print(processed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "\n",
      "\n",
      "Testing Metrics:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "\n",
      "\n",
      "Detailed Classification Report (Testing):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         default       1.00      1.00      1.00        27\n",
      "program transfer       1.00      1.00      1.00        23\n",
      "  state transfer       1.00      1.00      1.00        25\n",
      "\n",
      "        accuracy                           1.00        75\n",
      "       macro avg       1.00      1.00      1.00        75\n",
      "    weighted avg       1.00      1.00      1.00        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['statement'], df['target'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Creating a pipeline for TF-IDF vectorization and Logistic Regression\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(solver='liblinear')),\n",
    "])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on both training and testing data\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Function to calculate and print metrics\n",
    "def print_metrics(y_true, y_pred, dataset_type=\"Testing\"):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    print(f\"{dataset_type} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Evaluating the model\n",
    "print_metrics(y_train, train_predictions, \"Training\")\n",
    "print_metrics(y_test, test_predictions, \"Testing\")\n",
    "\n",
    "# Detailed classification report for testing data\n",
    "print(\"Detailed Classification Report (Testing):\")\n",
    "print(classification_report(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as text_classification_model.joblib\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the model to disk\n",
    "model_filename = 'text_classification_model.joblib'\n",
    "dump(model, model_filename)\n",
    "print(f\"Model saved as {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"statement\": \"initiate bulk transfer of 200 members for a specific program\", \"predicted_target\": \"program transfer\"}\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import json\n",
    "\n",
    "# Function to load the model and predict the target label for a given statement\n",
    "def predict_statement(statement):\n",
    "    # Load the model from disk\n",
    "    loaded_model = load(model_filename)\n",
    "    \n",
    "    # Predict the target for the given statement\n",
    "    predicted_target = loaded_model.predict([statement])[0]  # Assuming statement is a single string\n",
    "    \n",
    "    # Create a JSON object with the statement and predicted target\n",
    "    result_json = json.dumps({\"statement\": statement, \"predicted_target\": predicted_target})\n",
    "    \n",
    "    return result_json\n",
    "\n",
    "# Example usage\n",
    "statement = \"initiate bulk transfer of 200 members for a specific program\"\n",
    "result = predict_statement(statement)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"statement\": \"initiate bulk transfer of 200 members\", \"predicted_target\": \"default\"}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "statement = \"initiate bulk transfer of 200 members\"\n",
    "result = predict_statement(statement)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"statement\": \"initiate bulk transfer of 200 members for a state TX\", \"predicted_target\": \"state transfer\"}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "statement = \"initiate bulk transfer of 200 members for a state TX\"\n",
    "result = predict_statement(statement)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"preprocessed_statement\": \"initiate bulk transfer of 200 members for a state of\",\n",
      "    \"extracted_entities\": {\n",
      "        \"CARDINAL\": [\n",
      "            \"200\"\n",
      "        ]\n",
      "    },\n",
      "    \"predicted_target\": \"state transfer\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import json\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the custom preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Correct spelling using TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = str(blob.correct())\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    corrected_text = corrected_text.lower()\n",
    "    \n",
    "    # Additional preprocessing steps can be added here\n",
    "    \n",
    "    return corrected_text\n",
    "\n",
    "# Function to extract entities with spaCy\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {ent.label_: [] for ent in doc.ents}\n",
    "    for ent in doc.ents:\n",
    "        entities[ent.label_].append(ent.text)\n",
    "    return entities\n",
    "\n",
    "# Function to process JSON input and return required information in JSON format\n",
    "def process_json_input(input_json):\n",
    "    # Parse the JSON input\n",
    "    input_data = json.loads(input_json)\n",
    "    \n",
    "    # Extract \"statement\" and \"predicted_target\" from the input\n",
    "    statement = input_data.get(\"statement\", \"\")\n",
    "    predicted_target = input_data.get(\"predicted_target\", \"\")\n",
    "    \n",
    "    # Preprocess the statement\n",
    "    preprocessed_statement = preprocess_text(statement)\n",
    "    \n",
    "    # Extract entities from the preprocessed statement\n",
    "    extracted_entities = extract_entities(preprocessed_statement)\n",
    "    \n",
    "    # Prepare the output JSON object\n",
    "    output_data = {\n",
    "        \"preprocessed_statement\": preprocessed_statement,\n",
    "        \"extracted_entities\": extracted_entities,\n",
    "        \"predicted_target\": predicted_target\n",
    "    }\n",
    "    \n",
    "    return json.dumps(output_data, indent=4)\n",
    "\n",
    "\n",
    "# Process the input and print the output in JSON format\n",
    "output_json = process_json_input(result)\n",
    "print(output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
