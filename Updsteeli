import pandas as pd
import re
from dateutil.parser import parse
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D
import json

# Load the CSV file
df = pd.read_csv('messages.csv')

# Filter messages that contain "eligibility", "elig", or "eligible"
df = df[df['notes'].str.contains('eligibility|elig|eligible', case=False, na=False)]

# Preprocessing function
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)  # Remove numbers
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra spaces
    return text

# Preprocess all messages
df['cleaned_notes'] = df['notes'].apply(preprocess_text)

# Tokenization and padding
tokenizer = Tokenizer(num_words=5000, lower=True, oov_token="<OOV>")
tokenizer.fit_on_texts(df['cleaned_notes'])
sequences = tokenizer.texts_to_sequences(df['cleaned_notes'])
padded_sequences = pad_sequences(sequences, maxlen=100)

# Encode labels (assuming 'intent' column contains the actual labels for training)
label_encoder = LabelEncoder()
df['intent_encoded'] = label_encoder.fit_transform(df['intent'])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['intent_encoded'], test_size=0.2, random_state=0)

# Define the LSTM model
model = Sequential()
model.add(Embedding(input_dim=5000, output_dim=64, input_length=100))
model.add(SpatialDropout1D(0.2))
model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(len(label_encoder.classes_), activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the LSTM model
model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2, verbose=2)

# Predict intents for the test set
y_pred_prob = model.predict(X_test)
y_pred = y_pred_prob.argmax(axis=-1)

# Evaluate the model
classification_report_str = classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=1)
print(classification_report_str)

# Predict intents for all messages
df['predicted_intent_encoded'] = model.predict(padded_sequences).argmax(axis=-1)
df['predicted_intent'] = label_encoder.inverse_transform(df['predicted_intent_encoded'])

# Apply K-means clustering
vectorizer = TfidfVectorizer()
X_tfidf = vectorizer.fit_transform(df['cleaned_notes'])
num_clusters = 3
kmeans = KMeans(n_clusters=num_clusters, random_state=0)
kmeans.fit(X_tfidf)
df['cluster'] = kmeans.labels_

# Function to extract dates
def extract_dates(message):
    date_patterns = [
        r'\b\d{1,2}/\d{1,2}/\d{2,4}\b',  # Matches formats like 8/31/23, 02/29/24
        r'\b\d{1,2}-\d{1,2}-\d{2,4}\b',  # Matches formats like 8-31-23, 02-29-24
        r'\b\d{1,2}\s\w+\s\d{2,4}\b'  # Matches formats like 31 August 2023
    ]
    dates = []
    for pattern in date_patterns:
        found_dates = re.findall(pattern, message)
        for date_str in found_dates:
            try:
                dates.append(parse(date_str).date())
            except ValueError:
                continue
    return dates

# Add a new column for extracted dates
df['extracted_dates'] = df['notes'].apply(extract_dates)

# Function to categorize actions
def categorize_action(row):
    if row['predicted_intent'] == 'check':
        return 'Check eligibility'
    elif row['predicted_intent'] == 'close':
        return f"Close case on {row['extracted_dates'][0]}" if row['extracted_dates'] else "Close case"
    elif row['predicted_intent'] == 'monitor':
        return f"Monitor until {row['extracted_dates'][0] + pd.DateOffset(days=30)}" if row['extracted_dates'] else "Monitor"
    else:
        return "Inform"

# Add a new column for categorized actions
df['action'] = df.apply(categorize_action, axis=1)

# Convert the final output to JSON format
output_json = df[['notes', 'cluster', 'predicted_intent', 'extracted_dates', 'action']].to_json(orient='records')

# Print the classification report and JSON output
print(classification_report_str)
print(output_json)

# Save the JSON output to a file
with open('output.json', 'w') as json_file, open('output_table.txt', 'w') as table_file:
    json.dump(output_json, json_file)
    table_file.write(df[['notes', 'cluster', 'predicted_intent', 'extracted_dates', 'action']].to_string(index=False))

# Display the output in a tabular format
import ace_tools as tools; tools.display_dataframe_to_user(name="LSTM Output Analysis", dataframe=df[['notes', 'cluster', 'predicted_intent', 'extracted_dates', 'action']])
